"""GitHub é¡¹ç›®è¯„ä¼°åè°ƒå™¨ - è´Ÿè´£æ•°æ®æ”¶é›†å’Œè¯„ä¼°æµç¨‹"""

import asyncio
from datetime import datetime, timedelta, timezone
from typing import Optional

from nekro_agent.core import logger

from .client import GitHubClient
from .models import EvaluationCard, ProjectEvaluation, ProjectEvaluationData
from .scorer import ProjectScorer
from .utils import LRUCache


class GitHubProjectEvaluator:
    """GitHub é¡¹ç›®è¯„ä¼°å™¨ - åè°ƒæ•°æ®æ”¶é›†å’Œè¯„åˆ†"""

    # å…¨å±€ç¼“å­˜å®ä¾‹ï¼šå¸¦ 100 ä¸ªæ¡ç›®å®¹é‡å’Œ TTL é™åˆ¶çš„ LRU ç¼“å­˜
    _cache = LRUCache(max_size=100, ttl_seconds=1800)

    def __init__(self, client: GitHubClient):
        """åˆå§‹åŒ–è¯„ä¼°å™¨

        Args:
            client: GitHubClient å®ä¾‹
        """
        self.client = client
        self.scorer = ProjectScorer()

    async def evaluate_project(self, url: str) -> ProjectEvaluation:
        """æ‰§è¡Œå®Œæ•´çš„é¡¹ç›®è¯„ä¼°

        Args:
            url: GitHub é¡¹ç›® URL æˆ– owner/repo æ ¼å¼

        Returns:
            ProjectEvaluation è¯„ä¼°ç»“æœ

        Raises:
            ValueError: å¦‚æœ URL æ— æ•ˆæˆ–é¡¹ç›®ä¸å­˜åœ¨æˆ–é¡¹ç›®è¶…å¤§å‹
            RuntimeError: å¦‚æœæ•°æ®æ”¶é›†å¤±è´¥
        """
        # 0. æ£€æŸ¥ç¼“å­˜
        from .plugin import config

        cached_result = self._cache.get(url)
        if cached_result is not None:
            cache_age = cached_result.get("age_seconds", 0)
            logger.info(f"âœ… ä½¿ç”¨ç¼“å­˜ç»“æœ ({cache_age}ç§’å‰): {url}")
            return cached_result["result"]

        # 1. æ”¶é›†æ‰€æœ‰å¿…è¦æ•°æ®
        data = await self._collect_data(url)

        # 2. è®¡ç®—å„ç»´åº¦å¾—åˆ†
        scores = self.scorer.calculate_scores(data)

        # 3. ç”Ÿæˆä¼˜åŠ¿å’Œä¸è¶³
        strengths, weaknesses = self.scorer.generate_strengths_and_weaknesses(data, scores)

        # 4. ç”Ÿæˆæ¨èå»ºè®®
        total_score = scores["code_quality"].score + scores["activity"].score + scores["community_health"].score
        rating = self.scorer.get_rating(total_score)
        recommendation = self.scorer.generate_recommendation(total_score)

        # è®¡ç®—æ€»ä½“ confidence
        # v2.0 ä¸å†ä¾èµ– commits æ•°æ®ï¼Œæ‰€ä»¥æ€»æ˜¯ high
        overall_confidence = "high"

        # 5. ç”Ÿæˆå…³é”®æŒ‡æ ‡
        key_metrics = self._generate_key_metrics(data)

        # 6. ç”Ÿæˆæ€»ç»“
        summary = self._generate_summary(data)

        # 7. æ„å»ºè¯„ä¼°å¯¹è±¡
        evaluation = ProjectEvaluation(
            repo_full_name=data.full_name,
            repo_url=data.url,
            evaluated_at=datetime.now(timezone.utc),
            total_score=round(total_score, 1),
            confidence=overall_confidence,
            rating=rating,
            code_quality=scores["code_quality"],
            activity=scores["activity"],
            community_health=scores["community_health"],
            key_metrics=key_metrics,
            summary=summary,
            strengths=strengths,
            weaknesses=weaknesses,
            recommendation=recommendation,
        )

        # å­˜å‚¨åŸå§‹æ•°æ®ç”¨äºè°ƒè¯•
        self._last_evaluation_data = data

        # 8. ç¼“å­˜è¯„ä¼°ç»“æœ
        self._cache.set(url, {
            "result": evaluation,
            "age_seconds": 0,
        })
        logger.debug(f"ğŸ’¾ è¯„ä¼°ç»“æœå·²ç¼“å­˜: {url}")

        return evaluation

    def get_last_evaluation_raw_data(self) -> Optional["ProjectEvaluationData"]:
        """è·å–æœ€åä¸€æ¬¡è¯„ä¼°çš„åŸå§‹æ•°æ®ï¼ˆç”¨äºè°ƒè¯•ï¼‰

        Returns:
            ProjectEvaluationData æˆ– None
        """
        return getattr(self, "_last_evaluation_data", None)

    def generate_evaluation_card(
        self,
        evaluation: ProjectEvaluation,
        raw_data: ProjectEvaluationData,
    ) -> EvaluationCard:
        """ç”Ÿæˆå®Œæ•´çš„è¯„åˆ†å¡ç‰‡ï¼ŒåŒ…å«åŸå§‹æ•°æ®å’Œè¯„åˆ†ç‚¹åˆ†è§£

        Args:
            evaluation: é¡¹ç›®è¯„ä¼°ç»“æœ
            raw_data: åŸå§‹è¯„ä¼°æ•°æ®

        Returns:
            åŒ…å«å®Œæ•´ä¿¡æ¯çš„ EvaluationCard
        """
        from .formatter import EvaluationFormatter

        # ç”Ÿæˆè¯„åˆ†ç‚¹åˆ†è§£
        scores = self.scorer.calculate_scores(raw_data)
        scoring_breakdown = self.scorer.generate_scoring_breakdown(raw_data, scores)

        # ç”Ÿæˆå„ç§æ ¼å¼çš„è¾“å‡º
        formatter = EvaluationFormatter()
        markdown = formatter.to_markdown_card(evaluation)
        plain_text = formatter.to_detailed_scoring_report(evaluation, scoring_breakdown)

        # æ„å»ºè¯„åˆ†å¡ç‰‡
        return EvaluationCard(
            markdown=markdown,
            plain_text=plain_text,
            json_data=evaluation,
            raw_data=raw_data,
            scoring_breakdown=scoring_breakdown,
        )

    @classmethod
    def get_cache_stats(cls) -> dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯

        Returns:
            dict: ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        """
        return cls._cache.get_stats()

    @classmethod
    def clear_cache(cls) -> None:
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        cls._cache.clear()

    @classmethod
    def cleanup_expired_cache(cls) -> int:
        """æ¸…ç†è¿‡æœŸç¼“å­˜

        Returns:
            int: æ¸…ç†çš„æ¡ç›®æ•°
        """
        return cls._cache.cleanup_expired()

    async def _collect_data(self, url: str) -> ProjectEvaluationData:
        """é¡ºåºæ”¶é›†è¯„ä¼°æ‰€éœ€çš„æ‰€æœ‰æ•°æ®ï¼ˆç¡®ä¿å®Œæ•´æ€§ï¼‰

        Args:
            url: GitHub é¡¹ç›® URL

        Returns:
            ProjectEvaluationData åŒ…å«æ‰€æœ‰è¯„ä¼°æ•°æ®

        Raises:
            ValueError: å¦‚æœ URL æ— æ•ˆæˆ–é¡¹ç›®ä¸å­˜åœ¨
            RuntimeError: å¦‚æœæ•°æ®æ”¶é›†å¤±è´¥
        """
        # é¡ºåºè°ƒç”¨ APIï¼Œä¸æµ‹è¯•è„šæœ¬ä¿æŒä¸€è‡´
        logger.info(f"å¼€å§‹æ”¶é›†é¡¹ç›®æ•°æ®: {url}")

        # 1ï¸âƒ£ è·å–åŸºç¡€ä¿¡æ¯ï¼ˆå¿…éœ€ï¼Œå¦‚æœå¤±è´¥åˆ™æŠ›å‡ºå¼‚å¸¸ï¼‰
        logger.debug("ğŸ“‹ è·å–ä»“åº“åŸºç¡€ä¿¡æ¯...")
        repo_info = await self.client.get_repo_info(url)
        owner = repo_info.owner
        repo = repo_info.repo

        # 2ï¸âƒ£ è·å– README
        logger.debug("ğŸ“š è·å– README ä¿¡æ¯...")
        try:
            readme_info = await self.client.get_readme(url)
        except Exception as e:
            logger.warning(f"âš ï¸ README API è°ƒç”¨å¤±è´¥: {e}")
            readme_info = None

        # 3ï¸âƒ£ è·å– LICENSE
        logger.debug("ğŸ“„ è·å– LICENSE ä¿¡æ¯...")
        license_info = await self._safe_call(
            self.client.get_license(url),
            "license",
        )

        # 4ï¸âƒ£ è·å–ç¤¾åŒºå¥åº·æ–‡ä»¶
        logger.debug("ğŸ—£ï¸ è·å–ç¤¾åŒºå¥åº·æ–‡ä»¶...")
        community_profile = await self._safe_call(
            self.client.get_community_profile(url),
            "community_profile",
        )

        # 5ï¸âƒ£ è·å–è¯­è¨€ç»Ÿè®¡
        logger.debug("ğŸ”¤ è·å–è¯­è¨€ç»Ÿè®¡...")
        language_stats = await self._safe_call(
            self.client.get_languages(url),
            "language_stats",
        )

        # 5.5ï¸âƒ£ è·å–ä»“åº“ç»“æ„ï¼ˆæ£€æµ‹æ ‡å‡†ç›®å½•ï¼‰
        logger.debug("ğŸ“ è·å–ä»“åº“ç»“æ„...")
        repo_structure = await self._safe_call(
            self.client.get_repo_structure(url),
            "repo_structure",
        )

        # 6ï¸âƒ£ è·å– Issues åˆ—è¡¨
        logger.debug("ğŸ› è·å– Issues åˆ—è¡¨...")
        issues = await self._safe_call(
            self.client.get_issues(url, state="all", per_page=100),
            "issues",
        )

        # 9ï¸âƒ£ è·å– Pull Requests åˆ—è¡¨
        logger.debug("ğŸ”€ è·å– Pull Requests åˆ—è¡¨...")
        pull_requests = await self._safe_call(
            self.client.get_pull_requests(url, state="all", per_page=100),
            "pull_requests",
        )

        # ğŸ”Ÿ è·å– Releases åˆ—è¡¨
        logger.debug("ğŸ“¦ è·å– Releases åˆ—è¡¨...")
        releases = await self._safe_call(
            self.client.get_releases(url),
            "releases",
        )

        # ğŸ”³ è·å–åˆ†æ”¯åˆ—è¡¨
        logger.debug("ğŸŒ³ è·å–åˆ†æ”¯ä¿¡æ¯...")
        branches = await self._safe_call(
            self.client.get_branches(url),
            "branches",
        )

        logger.info("âœ… æ•°æ®æ”¶é›†å®Œæˆï¼Œå¼€å§‹æ•°æ®å¤„ç†...")

        # ===== å¤„ç†æ”¶é›†åˆ°çš„æ•°æ® =====
        # ä»£ç è´¨é‡æ•°æ®
        has_readme = readme_info is not None
        readme_length = len(readme_info.content) if readme_info else 0

        has_license = license_info is not None and not isinstance(license_info, Exception)
        license_name = license_info.name if not isinstance(license_info, Exception) else None

        # ç¤¾åŒºæ–‡ä»¶
        if not isinstance(community_profile, Exception):
            has_contributing = community_profile.has_contributing
            has_code_of_conduct = community_profile.has_code_of_conduct
        else:
            has_contributing = False
            has_code_of_conduct = False

        # è¯­è¨€ç»Ÿè®¡
        if not isinstance(language_stats, Exception):
            primary_language = language_stats.primary_language
            language_count = language_stats.language_count
            language_distribution = language_stats.language_percentages
        else:
            primary_language = repo_info.language
            language_count = 1 if repo_info.language else 0
            language_distribution = {repo_info.language: 100.0} if repo_info.language else {}

        # ===== æ£€æµ‹æ ‡å‡†ç›®å½•ç»“æ„ =====
        has_standard_dirs = False
        if not isinstance(repo_structure, Exception):
            standard_dirs = {"src", "lib", "tests", "test", "docs", "doc"}
            found_dirs = set()
            for item in repo_structure:
                if hasattr(item, "type") and item.type == "tree":
                    dir_name = item.path.split("/")[-1].lower() if hasattr(item, "path") else ""
                    if dir_name in standard_dirs:
                        found_dirs.add(dir_name)
            # æœ‰2ä¸ªæˆ–ä»¥ä¸Šçš„æ ‡å‡†ç›®å½•å°±è®¤ä¸ºç»“æ„æ¸…æ™°
            if len(found_dirs) >= 2:
                has_standard_dirs = True
                logger.debug(f"âœ… æ£€æµ‹åˆ°æ ‡å‡†ç›®å½•: {found_dirs}")
            elif len(found_dirs) == 1:
                logger.debug(f"âš ï¸ æ£€æµ‹åˆ°éƒ¨åˆ†æ ‡å‡†ç›®å½•: {found_dirs}")
        else:
            logger.debug("âš ï¸ è·å–ä»“åº“ç»“æ„å¤±è´¥ï¼Œæ— æ³•æ£€æµ‹æ ‡å‡†ç›®å½•")

        # ===== Release ç»Ÿè®¡ =====
        release_count = 0
        releases_last_year = 0
        if isinstance(releases, list):
            release_count = len(releases)

            one_year_ago = datetime.now(timezone.utc) - timedelta(days=365)
            for release in releases:
                try:
                    release_date = datetime.fromisoformat(
                        release.published_at.replace("Z", "+00:00"),
                    )
                    if release_date > one_year_ago:
                        releases_last_year += 1
                except:
                    pass

        # ===== Issue/PR ç»Ÿè®¡ =====
        open_issues_count = repo_info.issues
        closed_issues_count = 0
        issue_comments_total = 0
        total_prs = 0
        merged_prs = 0
        pr_comments_total = 0
        pr_comment_density = 0.0

        if isinstance(issues, list):
            for issue in issues:
                if not isinstance(issue, Exception):
                    if issue.state == "closed":
                        closed_issues_count += 1
                    # ç»Ÿè®¡ Issue è¯„è®ºæ€»æ•°
                    issue_comments_total += issue.comments

        if isinstance(pull_requests, list):
            total_prs = len(pull_requests)
            for pr in pull_requests:
                if not isinstance(pr, Exception):
                    if pr.merged:
                        merged_prs += 1
                    # ç»Ÿè®¡ PR è¯„è®ºæ€»æ•°
                    pr_comments_total += pr.comments

        # è®¡ç®—å¹³å‡å€¼å’Œå¯†åº¦
        issue_comments_avg = (
            issue_comments_total / max(1, open_issues_count + closed_issues_count)
            if (open_issues_count + closed_issues_count) > 0
            else 0.0
        )

        # PR è¯„è®ºå¯†åº¦ = (issue_comments + pr_comments) / merged_prs
        pr_comment_density = (issue_comments_total + pr_comments_total) / max(1, merged_prs) if merged_prs > 0 else 0.0

        # ===== åˆ†æ”¯ä¿æŠ¤ç»Ÿè®¡ =====
        protected_branches = 0
        if isinstance(branches, list):
            for branch in branches:
                if not isinstance(branch, Exception) and hasattr(branch, "is_protected") and branch.is_protected:
                    protected_branches += 1
                    logger.debug(f"ğŸ”’ å—ä¿æŠ¤åˆ†æ”¯: {branch.name}")

        # ===== ç¤¾åŒºæ•°æ® =====
        stars = repo_info.stars
        forks = repo_info.forks
        contributors = repo_info.contributors

        # ===== è®¡ç®—å­—æ®µ =====
        age_in_days = 0
        maintained_for_years = 0.0

        try:
            if repo_info.created_at:
                created_str = repo_info.created_at
                if created_str.endswith("Z"):
                    created_str = created_str.replace("Z", "+00:00")
                elif "+" not in created_str and "-" not in created_str[-6:]:
                    created_str = created_str + "+00:00"

                created_date = datetime.fromisoformat(created_str)
                age_in_days = (datetime.now(timezone.utc) - created_date).days
                logger.debug(f"âœ… é¡¹ç›®åˆ›å»ºæ—¶é—´: {created_date.strftime('%Y-%m-%d')}, å¹´é¾„: {age_in_days} å¤©")
        except Exception as e:
            logger.warning(f"âš ï¸ è§£æ created_at å¤±è´¥ ({repo_info.created_at}): {e}")

        try:
            if repo_info.updated_at:
                updated_str = repo_info.updated_at
                if updated_str.endswith("Z"):
                    updated_str = updated_str.replace("Z", "+00:00")
                elif "+" not in updated_str and "-" not in updated_str[-6:]:
                    updated_str = updated_str + "+00:00"

                updated_date = datetime.fromisoformat(updated_str)
                days_since_update = (datetime.now(timezone.utc) - updated_date).days
                # æŒç»­ç»´æŠ¤å¹´æ•° = (æœ€åä¸€æ¬¡æ›´æ–°è·ç°åœ¨çš„å¤©æ•°) / 365
                # è¿™åæ˜ äº†é¡¹ç›®æœ‰å¤šå°‘æ—¶é—´æ²¡æ›´æ–°
                maintained_for_years = max(0, (age_in_days - days_since_update) / 365)
                logger.debug(
                    f"âœ… æœ€åæ›´æ–°: {updated_date.strftime('%Y-%m-%d')}, è·ä»Š: {days_since_update} å¤©, æŒç»­ç»´æŠ¤: {maintained_for_years:.2f} å¹´",
                )
        except Exception as e:
            logger.warning(f"âš ï¸ è§£æ updated_at å¤±è´¥ ({repo_info.updated_at}): {e}")

        # æ„å»ºæ•°æ®å¯¹è±¡
        return ProjectEvaluationData(
            owner=owner,
            repo=repo,
            full_name=repo_info.full_name,
            description=repo_info.description,
            url=repo_info.url,
            created_at=(
                datetime.fromisoformat(repo_info.created_at.replace("Z", "+00:00"))
                if repo_info.created_at
                else datetime.now(timezone.utc)
            ),
            updated_at=(
                datetime.fromisoformat(repo_info.updated_at.replace("Z", "+00:00"))
                if repo_info.updated_at
                else datetime.now(timezone.utc)
            ),
            has_readme=has_readme,
            readme_length=readme_length,
            has_license=has_license,
            license_name=license_name,
            has_contributing=has_contributing,
            has_code_of_conduct=has_code_of_conduct,
            has_standard_dirs=has_standard_dirs,  # åŸºäºå®é™…æ£€æµ‹ç»“æœ
            primary_language=primary_language,
            language_count=language_count,
            language_distribution=language_distribution,
            release_count=release_count,
            releases_last_year=releases_last_year,
            open_issues=open_issues_count,
            closed_issues=closed_issues_count,
            issue_comments_total=issue_comments_total,
            issue_comments_avg=issue_comments_avg,
            total_prs=total_prs,
            merged_prs=merged_prs,
            pr_comments_total=pr_comments_total,
            pr_comment_density=pr_comment_density,
            protected_branches=protected_branches,
            stars=stars,
            forks=forks,
            contributors=contributors,
            age_in_days=age_in_days,
            maintained_for_years=maintained_for_years,
        )

    async def _safe_call(self, coro, name: str):
        """å®‰å…¨è°ƒç”¨ APIï¼Œè¿”å›å¼‚å¸¸è€Œä¸æ˜¯æŠ›å‡º

        Args:
            coro: åç¨‹
            name: API åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰

        Returns:
            API ç»“æœæˆ– Exception å¯¹è±¡
        """
        try:
            return await coro
        except Exception as e:
            logger.warning(f"âš ï¸ {name} API è°ƒç”¨å¤±è´¥: {type(e).__name__}: {str(e)[:100]}")
            return e

    @staticmethod
    def _generate_key_metrics(data: ProjectEvaluationData) -> dict:
        """ç”Ÿæˆå…³é”®æŒ‡æ ‡

        Args:
            data: é¡¹ç›®è¯„ä¼°åŸå§‹æ•°æ®

        Returns:
            å…³é”®æŒ‡æ ‡å­—å…¸
        """
        return {
            "stars": f"{data.stars:,}",
            "forks": f"{data.forks:,}",
            "contributors": f"{data.contributors}",
            "open_issues": f"{data.open_issues}",
            "release_count": f"{data.release_count}",
            "primary_language": data.primary_language or "æœªçŸ¥",
            "project_age_years": f"{data.age_in_days // 365}",
            "last_update": data.updated_at.strftime("%Y-%m-%d"),
        }

    @staticmethod
    def _generate_summary(data: ProjectEvaluationData) -> str:
        """ç”Ÿæˆè¯„ä¼°æ€»ç»“

        Args:
            data: é¡¹ç›®è¯„ä¼°åŸå§‹æ•°æ®

        Returns:
            è¯„ä¼°æ€»ç»“æ–‡æœ¬
        """
        parts = []

        # é¡¹ç›®åŸºæœ¬ç‰¹å¾
        if data.primary_language:
            parts.append(f"è¿™æ˜¯ä¸€ä¸ª {data.primary_language} é¡¹ç›®")
        else:
            parts.append("è¿™æ˜¯ä¸€ä¸ªå¼€æºé¡¹ç›®")

        # è§„æ¨¡
        if data.stars > 10000:
            parts.append("ï¼Œå¤‡å—å…³æ³¨ï¼ˆ10k+ Starsï¼‰")
        elif data.stars > 1000:
            parts.append("ï¼Œå…·æœ‰ä¸€å®šå½±å“åŠ›ï¼ˆ1k+ Starsï¼‰")
        elif data.stars > 100:
            parts.append("ï¼Œå·²è·å¾—ç¤¾åŒºè®¤å¯ï¼ˆ100+ Starsï¼‰")

        # æ´»è·ƒåº¦ - åŸºäº Release é¢‘ç‡å’Œé¡¹ç›®æ–°é²œåº¦
        from datetime import datetime, timezone

        days_since_update = (datetime.now(timezone.utc) - data.updated_at).days
        if days_since_update <= 30:
            parts.append("ï¼Œç»´æŠ¤æ´»è·ƒï¼ˆæœ€è¿‘æ›´æ–°ï¼‰")
        elif data.releases_last_year >= 4:
            parts.append("ï¼ŒæŒç»­ç»´æŠ¤ï¼ˆå®šæœŸå‘è¡Œï¼‰")
        else:
            parts.append("ï¼Œæ›´æ–°è¾ƒæ…¢")

        # ç¤¾åŒº
        if data.contributors >= 10:
            parts.append("ï¼Œç¤¾åŒºè§„æ¨¡è¾ƒå¤§")
        elif data.contributors > 0:
            parts.append("ï¼Œæœ‰è´¡çŒ®è€…å‚ä¸")

        return "ã€‚".join(parts) + "ã€‚"

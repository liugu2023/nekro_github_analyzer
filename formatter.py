"""GitHub é¡¹ç›®è¯„ä¼°ç»“æœæ ¼å¼åŒ–å™¨"""

from datetime import datetime, timezone

from .models import ProjectEvaluation, ProjectEvaluationData


class EvaluationFormatter:
    """è¯„ä¼°ç»“æœæ ¼å¼åŒ–å™¨ - ç”Ÿæˆå„ç§æ ¼å¼çš„è¾“å‡º"""

    @staticmethod
    def to_debug_report(evaluation: ProjectEvaluation, raw_data: ProjectEvaluationData) -> str:
        """ç”Ÿæˆè¯¦ç»†çš„è°ƒè¯•æŠ¥å‘Šï¼Œæ˜¾ç¤ºåŸå§‹æ•°æ®å’Œè¯„åˆ†å¯¹æ¯”

        Args:
            evaluation: é¡¹ç›®è¯„ä¼°ç»“æœ
            raw_data: åŸå§‹è¯„ä¼°æ•°æ®

        Returns:
            è¯¦ç»†çš„è°ƒè¯•æŠ¥å‘Š
        """
        lines = []

        # ===== æ ‡é¢˜ =====
        lines.append("# ğŸ” GitHub é¡¹ç›®è¯„ä¼°è¯¦ç»†è°ƒè¯•æŠ¥å‘Š\n")
        lines.append(f"## é¡¹ç›®: {evaluation.repo_full_name}\n")
        lines.append("---\n")

        # ===== åŸå§‹æ•°æ® - ä»£ç è´¨é‡ç›¸å…³ =====
        lines.append("## ğŸ“Š ã€åŸå§‹æ•°æ®ã€‘ä»£ç è´¨é‡æŒ‡æ ‡\n")
        lines.append(f"- has_readme: {raw_data.has_readme}\n")
        lines.append(f"- readme_length: {raw_data.readme_length} å­—ç¬¦\n")
        lines.append(f"- has_license: {raw_data.has_license}\n")
        lines.append(f"- license_name: {raw_data.license_name}\n")
        lines.append(f"- has_contributing: {raw_data.has_contributing}\n")
        lines.append(f"- has_code_of_conduct: {raw_data.has_code_of_conduct}\n")
        lines.append(f"- has_standard_dirs: {raw_data.has_standard_dirs}\n")
        lines.append(f"- primary_language: {raw_data.primary_language}\n")
        lines.append(f"- language_count: {raw_data.language_count}\n")
        lines.append(f"- language_distribution: {raw_data.language_distribution}\n")

        lines.append("\n### ğŸ’¡ è¯„åˆ†ç»“æœ\n")
        cq = evaluation.code_quality
        lines.append(f"**ä»£ç è´¨é‡å¾—åˆ†: {cq.score:.1f}/{cq.max_score} ({cq.percentage:.1f}%)**\n")
        lines.append("è¯„åˆ†è¯¦æƒ…:\n")
        for key, value in cq.details.items():
            lines.append(f"  - {key}: {value}\n")

        # ===== åŸå§‹æ•°æ® - æ´»è·ƒåº¦ç›¸å…³ =====
        lines.append("\n---\n")
        lines.append("## ğŸ“Š ã€åŸå§‹æ•°æ®ã€‘é¡¹ç›®æ´»è·ƒåº¦æŒ‡æ ‡ (v2.0)\n")
        lines.append(f"- updated_at: {raw_data.updated_at.strftime('%Y-%m-%d %H:%M:%S')}\n")
        days_since_update = (datetime.now(timezone.utc) - raw_data.updated_at).days
        lines.append(f"- days_since_update: {days_since_update} å¤©\n")
        lines.append(f"- release_count: {raw_data.release_count}\n")
        lines.append(f"- releases_last_year: {raw_data.releases_last_year}\n")
        lines.append(f"- open_issues: {raw_data.open_issues}\n")
        lines.append(f"- closed_issues: {raw_data.closed_issues}\n")
        lines.append(f"- issue_comments_total: {raw_data.issue_comments_total} æ¡\n")
        lines.append(f"- issue_comments_avg: {raw_data.issue_comments_avg:.2f} æ¡/issue\n")
        lines.append(f"- total_prs: {raw_data.total_prs}\n")
        lines.append(f"- merged_prs: {raw_data.merged_prs}\n")
        lines.append(f"- pr_comments_total: {raw_data.pr_comments_total} æ¡\n")
        lines.append(f"- pr_comment_density: {raw_data.pr_comment_density:.2f} æ¡/merged_pr\n")
        lines.append(f"- protected_branches: {raw_data.protected_branches}\n")

        # è®¡ç®—å…³é”®æ¯”ç‡
        if raw_data.open_issues + raw_data.closed_issues > 0:
            issue_close_rate = (raw_data.closed_issues / (raw_data.open_issues + raw_data.closed_issues)) * 100
            lines.append(f"- ğŸ“ˆ Issue å…³é—­ç‡: {issue_close_rate:.1f}%\n")

        if raw_data.total_prs > 0:
            pr_merge_rate = (raw_data.merged_prs / raw_data.total_prs) * 100
            lines.append(f"- ğŸ“ˆ PR åˆå¹¶ç‡: {pr_merge_rate:.1f}%\n")

        lines.append("\n**â„¹ï¸ æ•°æ®æ¥æºè¯´æ˜:**\n")
        lines.append("- `releases_last_year`: è¿‡å»ä¸€å¹´å†…å‘å¸ƒçš„ç‰ˆæœ¬æ•°ï¼ˆv2.0æ ¸å¿ƒæŒ‡æ ‡ï¼‰\n")
        lines.append("- `updated_at`: é¡¹ç›®æœ€åæ›´æ–°æ—¶é—´ï¼ˆv2.0æ ¸å¿ƒæŒ‡æ ‡ï¼‰\n")

        lines.append("\n### ğŸ’¡ è¯„åˆ†ç»“æœ\n")
        activity = evaluation.activity
        lines.append(f"**é¡¹ç›®æ´»è·ƒåº¦å¾—åˆ†: {activity.score:.1f}/{activity.max_score} ({activity.percentage:.1f}%)**\n")
        lines.append("è¯„åˆ†è¯¦æƒ…:\n")
        for key, value in activity.details.items():
            lines.append(f"  - {key}: {value}\n")

        # ===== åŸå§‹æ•°æ® - ç¤¾åŒºå¥åº·åº¦ç›¸å…³ =====
        lines.append("\n---\n")
        lines.append("## ğŸ“Š ã€åŸå§‹æ•°æ®ã€‘ç¤¾åŒºå¥åº·åº¦æŒ‡æ ‡\n")
        lines.append(f"- stars: {raw_data.stars}\n")
        lines.append(f"- forks: {raw_data.forks}\n")
        lines.append(f"- contributors: {raw_data.contributors}\n")
        lines.append(f"- age_in_days: {raw_data.age_in_days} å¤©\n")
        lines.append(f"- maintained_for_years: {raw_data.maintained_for_years:.2f} å¹´\n")

        # è®¡ç®—å…³é”®æ¯”ç‡
        if raw_data.forks > 0:
            star_fork_ratio = raw_data.stars / raw_data.forks
            lines.append(f"- ğŸ“ˆ Star/Fork æ¯”ç‡: {star_fork_ratio:.2f}\n")

        if raw_data.stars > 0:
            issue_ratio = raw_data.open_issues / raw_data.stars
            lines.append(f"- ğŸ“ˆ Open Issues/Stars æ¯”ç‡: {issue_ratio:.4f}\n")

        lines.append("\n### ğŸ’¡ è¯„åˆ†ç»“æœ\n")
        ch = evaluation.community_health
        lines.append(f"**ç¤¾åŒºå¥åº·åº¦å¾—åˆ†: {ch.score:.1f}/{ch.max_score} ({ch.percentage:.1f}%)**\n")
        lines.append("è¯„åˆ†è¯¦æƒ…:\n")
        for key, value in ch.details.items():
            lines.append(f"  - {key}: {value}\n")

        # ===== ç»¼åˆè¯„åˆ†æ±‡æ€» =====
        lines.append("\n---\n")
        lines.append("## ğŸ“Š ç»¼åˆè¯„åˆ†æ±‡æ€»\n")
        lines.append(f"**ä»£ç è´¨é‡**: {evaluation.code_quality.score:.1f}/30 ({evaluation.code_quality.percentage:.1f}%)\n")
        lines.append(f"**é¡¹ç›®æ´»è·ƒåº¦**: {evaluation.activity.score:.1f}/40 ({evaluation.activity.percentage:.1f}%)\n")
        lines.append(
            f"**ç¤¾åŒºå¥åº·åº¦**: {evaluation.community_health.score:.1f}/30 ({evaluation.community_health.percentage:.1f}%)\n",
        )
        lines.append(f"\n**æ€»åˆ†**: {evaluation.total_score:.1f}/100\n")
        lines.append(f"**è¯„çº§**: {evaluation.rating}\n")

        # ===== æ•°æ®è´¨é‡è¯Šæ–­ =====
        lines.append("\n---\n")
        lines.append("## ğŸ”§ æ•°æ®è´¨é‡è¯Šæ–­ (v2.0)\n")
        lines.append("### âš ï¸ å¯èƒ½çš„é—®é¢˜\n")

        # v2.0è¯Šæ–­é€»è¾‘
        days_since_update = (datetime.now(timezone.utc) - raw_data.updated_at).days
        if days_since_update > 365:
            lines.append(f"- **é¡¹ç›®é•¿æœŸåœæ»**: {days_since_update}å¤©æœªæ›´æ–°\n")
            lines.append("  â†’ å¯èƒ½å­˜åœ¨ç»´æŠ¤é£é™©\n")

        if raw_data.releases_last_year < 1:
            lines.append("- **æ— æ­£å¼å‘è¡Œç‰ˆæœ¬**: è¿‡å»ä¸€å¹´å†…æœªå‘å¸ƒä»»ä½•ç‰ˆæœ¬\n")
            lines.append("  â†’ å¯èƒ½éš¾ä»¥è·å¾—ç¨³å®šä½¿ç”¨ä½“éªŒ\n")

        if raw_data.open_issues > raw_data.closed_issues * 2:
            lines.append(f"- **Open Issueså †ç§¯**: {raw_data.open_issues} ä¸ªæœªå…³é—­é—®é¢˜\n")
            lines.append("  â†’ å¯èƒ½éœ€è¦æ›´å¤šç»´æŠ¤äººåŠ›\n")

        lines.append("\n### ğŸ“Œ å»ºè®®\n")
        lines.append("å¦‚æœè¯„åˆ†ä¸å®é™…ä¸ç¬¦ï¼Œå¯èƒ½éœ€è¦:\n")
        lines.append("1. æŸ¥çœ‹é¡¹ç›®çš„Releasesé¡µé¢äº†è§£å‘ç‰ˆé¢‘ç‡\n")
        lines.append("2. æ£€æŸ¥é¡¹ç›®çš„æœ€è¿‘æ›´æ–°: ç‚¹å‡»GitHubä¸Šçš„ 'Commits' æŸ¥çœ‹æœ€æ–°æ´»åŠ¨\n")
        lines.append("3. æŸ¥çœ‹Open Issueså’ŒPRçš„æ´»è·ƒåº¦\n")

        # ===== ä¼˜ç¼ºç‚¹åˆ†æ =====
        lines.append("\n---\n")
        lines.append("## ğŸ“‹ è¯„ä¼°æ€»ç»“\n")

        if evaluation.strengths:
            lines.append("### ğŸ’ª ä¸»è¦ä¼˜åŠ¿\n")
            for strength in evaluation.strengths:
                lines.append(f"- {strength}\n")

        if evaluation.weaknesses:
            lines.append("\n### âš ï¸ å¯æ”¹è¿›ä¹‹å¤„\n")
            for weakness in evaluation.weaknesses:
                lines.append(f"- {weakness}\n")

        lines.append("\n### ğŸ¯ æ¨èå»ºè®®\n")
        lines.append(f"{evaluation.recommendation}\n")

        return "".join(lines)

    @staticmethod
    def to_brief_report(evaluation: ProjectEvaluation) -> str:
        """ç”Ÿæˆç®€æ´æŠ¥å‘Šï¼ˆé™åˆ¶åœ¨1000å­—ç¬¦å†…ï¼‰

        Args:
            evaluation: é¡¹ç›®è¯„ä¼°ç»“æœ

        Returns:
            ç®€æ´çš„è¯„ä¼°æŠ¥å‘Š
        """
        lines = []

        # æ ‡é¢˜å’Œæ€»åˆ†
        lines.append(f"ğŸ“Š **{evaluation.repo_full_name}**\n")
        lines.append(f"æ€»åˆ†: **{evaluation.total_score:.1f}/100** | è¯„çº§: **{evaluation.rating}**\n")

        # è¯„åˆ†ç»†åˆ†
        lines.append("\nğŸ“Œ ç»´åº¦è¯„åˆ†:\n")
        lines.append(f"- ä»£ç è´¨é‡: {evaluation.code_quality.score:.1f}/{evaluation.code_quality.max_score}\n")
        lines.append(f"- é¡¹ç›®æ´»è·ƒ: {evaluation.activity.score:.1f}/{evaluation.activity.max_score}\n")
        lines.append(f"- ç¤¾åŒºå¥åº·: {evaluation.community_health.score:.1f}/{evaluation.community_health.max_score}\n")

        # å…³é”®æŒ‡æ ‡
        lines.append("\nğŸ¯ å…³é”®æŒ‡æ ‡:\n")
        if evaluation.key_metrics:
            for key, value in list(evaluation.key_metrics.items())[:5]:  # ä»…æ˜¾ç¤ºå‰5ä¸ª
                lines.append(f"- {key}: {value}\n")

        # ä¼˜ç¼ºç‚¹ï¼ˆç®€çŸ­ç‰ˆï¼‰
        if evaluation.strengths:
            lines.append("\nâœ… ä¼˜åŠ¿:\n")
            for s in evaluation.strengths[:2]:  # ä»…æ˜¾ç¤ºå‰2ä¸ª
                lines.append(f"- {s}\n")

        if evaluation.weaknesses:
            lines.append("\nâš ï¸ ä¸è¶³:\n")
            for w in evaluation.weaknesses[:2]:  # ä»…æ˜¾ç¤ºå‰2ä¸ª
                lines.append(f"- {w}\n")

        # å»ºè®®
        lines.append(f"\nğŸ’¡ {evaluation.recommendation}\n")

        report = "".join(lines)

        # æ£€æŸ¥é•¿åº¦ï¼Œå¦‚æœè¶…è¿‡1000å­—ç¬¦å°±è¿›ä¸€æ­¥æˆªæ–­
        if len(report) > 1000:
            report = report[:1000] + "..."

        return report

    @staticmethod
    def to_markdown_card(evaluation: ProjectEvaluation) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼çš„è¯„åˆ†å¡ç‰‡

        Args:
            evaluation: é¡¹ç›®è¯„ä¼°ç»“æœ

        Returns:
            Markdown æ ¼å¼çš„è¯„åˆ†å¡ç‰‡
        """
        lines = []

        # ===== æ ‡é¢˜å’Œæ€»åˆ† =====
        lines.append("# ğŸ¯ GitHub é¡¹ç›®è¯„ä¼°æŠ¥å‘Š\n")
        lines.append(
            f"## ğŸ“Š ç»¼åˆè¯„åˆ†: **{evaluation.total_score:.1f}/100** | è¯„çº§: **{evaluation.rating}**\n",
        )
        lines.append("---\n")

        # ===== ç»´åº¦å¾—åˆ† =====
        lines.append("## ğŸ“ˆ ç»´åº¦å¾—åˆ†\n")

        # ä»£ç è´¨é‡
        cq = evaluation.code_quality
        lines.append(f"### ğŸ”¨ ä»£ç è´¨é‡: {cq.score:.1f}/{cq.max_score}\n")
        for key, value in cq.details.items():
            lines.append(f"- **{key}**: {value}\n")

        # æ´»è·ƒåº¦
        lines.append("")
        activity = evaluation.activity
        lines.append(f"### ğŸš€ é¡¹ç›®æ´»è·ƒåº¦: {activity.score:.1f}/{activity.max_score}\n")
        for key, value in activity.details.items():
            lines.append(f"- **{key}**: {value}\n")

        # ç¤¾åŒºå¥åº·åº¦
        lines.append("")
        ch = evaluation.community_health
        lines.append(f"### ğŸŒŸ ç¤¾åŒºå¥åº·åº¦: {ch.score:.1f}/{ch.max_score}\n")
        for key, value in ch.details.items():
            lines.append(f"- **{key}**: {value}\n")

        # ===== å…³é”®æŒ‡æ ‡ =====
        lines.append("\n## ğŸ’¡ å…³é”®æŒ‡æ ‡\n")
        lines.append("| æŒ‡æ ‡ | æ•°å€¼ |\n")
        lines.append("|------|------|\n")

        # æ„å»ºæŒ‡æ ‡è¡¨æ ¼
        metrics_map = {
            "â­ Stars": "stars",
            "ğŸ”€ Forks": "forks",
            "ğŸ‘¥ Contributors": "contributors",
            "ğŸ“Š å‘¨å‡ Commits": "commits_per_week",
            "ğŸ“‹ Open Issues": "open_issues",
            "ğŸ“ æœ€è¿‘ 3 æœˆ Commits": "recent_commits",
            "ğŸ“¦ Release æ•°": "release_count",
            "ğŸ’» ä¸»è¦è¯­è¨€": "primary_language",
            "ğŸ“… é¡¹ç›®å¹´é¾„": "project_age_years",
        }

        for label, key in metrics_map.items():
            if key in evaluation.key_metrics:
                value = evaluation.key_metrics[key]
                lines.append(f"| {label} | {value} |\n")

        # ===== è¯„ä¼°æ€»ç»“ =====
        lines.append("\n## âœ¨ è¯„ä¼°æ€»ç»“\n")

        if evaluation.summary:
            lines.append(f"{evaluation.summary}\n\n")

        # ä¼˜åŠ¿
        if evaluation.strengths:
            lines.append("### ğŸ’ª ä¸»è¦ä¼˜åŠ¿\n")
            for strength in evaluation.strengths:
                lines.append(f"- {strength}\n")
            lines.append("")

        # ä¸è¶³
        if evaluation.weaknesses:
            lines.append("### âš ï¸ å¯æ”¹è¿›ä¹‹å¤„\n")
            for weakness in evaluation.weaknesses:
                lines.append(f"- {weakness}\n")
            lines.append("")

        # æ¨èå»ºè®®
        lines.append("### ğŸ¯ æ¨èå»ºè®®\n")
        lines.append(f"{evaluation.recommendation}\n")

        # ===== å°¾éƒ¨ä¿¡æ¯ =====
        lines.append("\n---\n")
        lines.append(f"**è¯„ä¼°æ—¶é—´**: {evaluation.evaluated_at.strftime('%Y-%m-%d %H:%M:%S')} UTC\n")
        lines.append(f"**é¡¹ç›®é“¾æ¥**: [{evaluation.repo_full_name}]({evaluation.repo_url})\n")
        lines.append("**æ•°æ®æ¥æº**: GitHub API\n")

        return "".join(lines)

    @staticmethod
    def to_plain_text(evaluation: ProjectEvaluation) -> str:
        """ç”Ÿæˆçº¯æ–‡æœ¬æ ¼å¼çš„è¯„ä¼°æŠ¥å‘Š

        Args:
            evaluation: é¡¹ç›®è¯„ä¼°ç»“æœ

        Returns:
            çº¯æ–‡æœ¬æ ¼å¼çš„è¯„ä¼°æŠ¥å‘Š
        """
        lines = []

        # æ ‡é¢˜
        lines.append("=" * 70)
        lines.append("GitHub é¡¹ç›®è¯„ä¼°æŠ¥å‘Š")
        lines.append("=" * 70)
        lines.append("")

        # é¡¹ç›®ä¿¡æ¯
        lines.append(f"é¡¹ç›®: {evaluation.repo_full_name}")
        lines.append(f"é“¾æ¥: {evaluation.repo_url}")
        lines.append(f"è¯„ä¼°æ—¶é—´: {evaluation.evaluated_at.strftime('%Y-%m-%d %H:%M:%S')} UTC")
        lines.append("")

        # æ€»åˆ†
        lines.append("-" * 70)
        lines.append(f"ç»¼åˆè¯„åˆ†: {evaluation.total_score:.1f}/100 | è¯„çº§: {evaluation.rating}")
        lines.append("-" * 70)
        lines.append("")

        # ç»´åº¦å¾—åˆ†
        lines.append("ã€ç»´åº¦å¾—åˆ†ã€‘")
        lines.append(f"  ä»£ç è´¨é‡: {evaluation.code_quality.score:.1f}/{evaluation.code_quality.max_score}")
        lines.append(f"  é¡¹ç›®æ´»è·ƒåº¦: {evaluation.activity.score:.1f}/{evaluation.activity.max_score}")
        lines.append(f"  ç¤¾åŒºå¥åº·åº¦: {evaluation.community_health.score:.1f}/{evaluation.community_health.max_score}")
        lines.append("")

        # å…³é”®æŒ‡æ ‡
        lines.append("ã€å…³é”®æŒ‡æ ‡ã€‘")
        for key, value in evaluation.key_metrics.items():
            lines.append(f"  {key}: {value}")
        lines.append("")

        # ä¼˜åŠ¿
        if evaluation.strengths:
            lines.append("ã€ä¸»è¦ä¼˜åŠ¿ã€‘")
            for strength in evaluation.strengths:
                lines.append(f"  âœ“ {strength}")
            lines.append("")

        # ä¸è¶³
        if evaluation.weaknesses:
            lines.append("ã€å¯æ”¹è¿›ä¹‹å¤„ã€‘")
            for weakness in evaluation.weaknesses:
                lines.append(f"  âœ— {weakness}")
            lines.append("")

        # æ¨è
        lines.append("ã€æ¨èå»ºè®®ã€‘")
        lines.append(evaluation.recommendation)
        lines.append("")

        lines.append("=" * 70)

        return "\n".join(lines)

    @staticmethod
    def to_detailed_scoring_report(
        evaluation: ProjectEvaluation,
        scoring_breakdown: dict,
    ) -> str:
        """ç”Ÿæˆè¯¦ç»†çš„è¯„åˆ†é€é¡¹æŠ¥å‘Šï¼ˆæ¯è¡Œä¸€ä¸ªæ£€æŸ¥é¡¹ï¼‰

        Args:
            evaluation: é¡¹ç›®è¯„ä¼°ç»“æœ
            scoring_breakdown: è¯„åˆ†ç‚¹åˆ†è§£

        Returns:
            æ ¼å¼åŒ–çš„è¯¦ç»†è¯„åˆ†æŠ¥å‘Š
        """
        lines = []

        # ===== æ ‡é¢˜å’Œæ€»åˆ† =====
        total_score = evaluation.total_score
        lines.append("=" * 80)
        lines.append(f"ğŸ¯ ç»¼åˆè¯„åˆ†: {total_score}/100 | è¯„çº§: {evaluation.rating}")
        lines.append(f"ğŸ“Š æ•°æ®å¯ä¿¡åº¦: {evaluation.confidence}")
        lines.append("=" * 80)
        lines.append("")

        # ===== ä»£ç è´¨é‡ç»´åº¦ =====
        lines.append("ğŸ“ ã€ä»£ç è´¨é‡ã€‘30åˆ†")
        lines.append("-" * 80)
        cq_breakdown = scoring_breakdown["code_quality"]
        cq_score = cq_breakdown["total_score"]
        lines.append(f"å½“å‰å¾—åˆ†: {cq_score}/30 ({cq_breakdown['percentage']:.1f}%)")
        lines.append(f"å¯ä¿¡åº¦: {cq_breakdown['confidence']}")
        lines.append("")

        # è¯¦ç»†æ£€æŸ¥é¡¹
        raw_cq = cq_breakdown["raw_metrics"]

        # README
        readme_status = "âœ“" if raw_cq["has_readme"] else "âœ—"
        readme_detail = f"(é•¿åº¦: {raw_cq['readme_length']} å­—ç¬¦)" if raw_cq["has_readme"] else "(ç¼ºå¤±)"
        lines.append(f"  {readme_status} READMEæ–‡æ¡£: {readme_detail}")
        if raw_cq["has_readme"] and raw_cq["readme_length"] >= 500:
            lines.append("     â†’ å¾—åˆ†: +5 åˆ† (ä¼˜ç§€)")
        elif raw_cq["has_readme"]:
            lines.append("     â†’ å¾—åˆ†: +3 åˆ† (è‰¯å¥½)")
        else:
            lines.append("     â†’ å¾—åˆ†: 0 åˆ† (ç¼ºå¤±)")

        # LICENSE
        license_status = "âœ“" if raw_cq["has_license"] else "âœ—"
        license_name = raw_cq.get("license_name", "æ— ")
        lines.append(f"  {license_status} è®¸å¯è¯: {license_name}")
        lines.append(f"     â†’ å¾—åˆ†: {'2 åˆ†' if raw_cq['has_license'] else '0 åˆ†'}")

        # CONTRIBUTING
        contrib_status = "âœ“" if raw_cq["has_contributing"] else "âœ—"
        lines.append(f"  {contrib_status} è´¡çŒ®æŒ‡å—")
        lines.append(f"     â†’ å¾—åˆ†: {'1.5 åˆ†' if raw_cq['has_contributing'] else '0 åˆ†'}")

        # CODE_OF_CONDUCT
        coc_status = "âœ“" if raw_cq.get("has_code_of_conduct") else "âœ—"
        lines.append(f"  {coc_status} è¡Œä¸ºå‡†åˆ™")
        lines.append(f"     â†’ å¾—åˆ†: {'1.5 åˆ†' if raw_cq.get('has_code_of_conduct') else '0 åˆ†'}")

        # ä¸»è¯­è¨€
        lines.append(f"  ğŸ”§ ä¸»è¦è¯­è¨€: {raw_cq['primary_language']}")
        lines.append("     â†’ å¾—åˆ†: 3 åˆ†")

        # è¯­è¨€å¤šæ ·æ€§
        lang_count = raw_cq["language_count"]
        if 1 <= lang_count <= 5:
            lang_level = "åˆç†"
            lang_score = 4
        elif 5 < lang_count <= 10:
            lang_level = "å¯æ¥å—"
            lang_score = 2
        elif lang_count > 10:
            lang_level = "è¿‡åº¦åˆ†æ•£"
            lang_score = 0
        else:
            lang_level = "æœªè¯†åˆ«"
            lang_score = 0
        lines.append(f"  ğŸ“š è¯­è¨€å¤šæ ·æ€§: {lang_count} ç§è¯­è¨€ ({lang_level})")
        lines.append(f"     â†’ å¾—åˆ†: {lang_score} åˆ†")

        # æ ‡å‡†ç›®å½•
        std_dirs_status = "âœ“" if raw_cq["has_standard_dirs"] else "âœ—"
        lines.append(f"  {std_dirs_status} æ ‡å‡†ç›®å½•ç»“æ„")
        lines.append(f"     â†’ å¾—åˆ†: {'3 åˆ†' if raw_cq['has_standard_dirs'] else '0-1.5 åˆ†'}")

        # Releaseç®¡ç†
        release_count = raw_cq["release_count"]
        if release_count >= 4:
            release_level = "è§„èŒƒ"
            release_score = 3
        elif release_count >= 2:
            release_level = "åŸºç¡€"
            release_score = 2
        elif release_count >= 1:
            release_level = "åˆçº§"
            release_score = 1
        else:
            release_level = "æ— "
            release_score = 0
        lines.append(f"  ğŸ“¦ Releaseç®¡ç†: {release_count} ä¸ªå‘è¡Œç‰ˆ ({release_level})")
        lines.append(f"     â†’ å¾—åˆ†: {release_score} åˆ†")

        # åˆ†æ”¯ä¿æŠ¤
        protected = raw_cq["protected_branches"]
        lines.append(f"  ğŸ”’ åˆ†æ”¯ä¿æŠ¤: {protected} ä¸ªå—ä¿æŠ¤åˆ†æ”¯")
        lines.append(f"     â†’ å¾—åˆ†: {min(2, protected * 0.5)} åˆ†")

        lines.append(f"\n   ã€ä»£ç è´¨é‡è¯¦æƒ…ã€‘{dict(cq_breakdown['details'])}")
        lines.append("")

        # ===== æ´»è·ƒåº¦ç»´åº¦ =====
        lines.append("ğŸš€ ã€é¡¹ç›®æ´»è·ƒåº¦ã€‘40åˆ†")
        lines.append("-" * 80)
        activity_breakdown = scoring_breakdown["activity"]
        activity_score = activity_breakdown["total_score"]
        lines.append(f"å½“å‰å¾—åˆ†: {activity_score}/40 ({activity_breakdown['percentage']:.1f}%)")
        lines.append(f"å¯ä¿¡åº¦: {activity_breakdown['confidence']}")
        lines.append("")

        raw_activity = activity_breakdown["raw_metrics"]

        # Release å‘å¸ƒé¢‘ç‡ (v2.0æ–°æŒ‡æ ‡)
        releases = raw_activity.get("releases_last_year", 0)
        if releases >= 6:
            release_freq_level = "é«˜é¢‘ (â‰¥6æ¬¡/å¹´)"
            release_freq_score = 12
        elif releases >= 4:
            release_freq_level = "ä¸­ä¸Š (4-5æ¬¡/å¹´)"
            release_freq_score = 10
        elif releases >= 2:
            release_freq_level = "ä¸­ç­‰ (2-3æ¬¡/å¹´)"
            release_freq_score = 7
        elif releases >= 1:
            release_freq_level = "ä½é¢‘ (1æ¬¡/å¹´)"
            release_freq_score = 4
        else:
            release_freq_level = "æ— å‘è¡Œ"
            release_freq_score = 0

        lines.append(f"  ğŸ“¦ Releaseå‘å¸ƒé¢‘ç‡: {releases}æ¬¡/å¹´ ({release_freq_level})")
        lines.append(f"     â†’ å¾—åˆ†: {release_freq_score} åˆ†")

        # é¡¹ç›®æ–°é²œåº¦ (v2.0æ–°æŒ‡æ ‡)
        days_since_update = raw_activity.get("days_since_update", 0)
        if days_since_update <= 30:
            freshness_level = "ğŸŸ¢ æŒç»­æ´»è·ƒ"
            freshness_score = 15
        elif days_since_update <= 90:
            freshness_level = "ğŸŸ¡ å®šæœŸç»´æŠ¤"
            freshness_score = 12
        elif days_since_update <= 180:
            freshness_level = "ğŸŸ  ä¸å¤ªé¢‘ç¹"
            freshness_score = 8
        elif days_since_update <= 365:
            freshness_level = "ğŸ”´ é•¿æœŸåœæ»"
            freshness_score = 4
        else:
            freshness_level = "âš« å·²æ”¾å¼ƒ"
            freshness_score = 0

        lines.append(f"  ğŸ• é¡¹ç›®æ–°é²œåº¦: {days_since_update}å¤©æœªæ›´æ–° ({freshness_level})")
        lines.append(f"     â†’ å¾—åˆ†: {freshness_score} åˆ†")

        # Issueç»Ÿè®¡
        open_issues = raw_activity["open_issues"]
        closed_issues = raw_activity["closed_issues"]
        issue_close_rate = raw_activity["issue_close_rate"]

        lines.append(f"  ğŸ“‹ Issueç®¡ç†: {open_issues} å¼€æ”¾ | {closed_issues} å·²å…³é—­")
        lines.append(f"     å…³é—­ç‡: {issue_close_rate:.1f}%")
        lines.append(f"     â†’ å¾—åˆ†: {min(5, issue_close_rate / 20):.1f} åˆ†")

        # PRç»Ÿè®¡
        total_prs = raw_activity["total_prs"]
        merged_prs = raw_activity["merged_prs"]
        pr_merge_rate = raw_activity["pr_merge_rate"]

        lines.append(f"  ğŸ”€ PRç®¡ç†: {total_prs} ä¸ªPR | {merged_prs} å·²åˆå¹¶")
        lines.append(f"     åˆå¹¶ç‡: {pr_merge_rate:.1f}%")
        lines.append(f"     â†’ å¾—åˆ†: {min(5, pr_merge_rate / 20):.1f} åˆ†")

        lines.append(f"\n   ã€æ´»è·ƒåº¦è¯¦æƒ…ã€‘{dict(activity_breakdown['details'])}")
        lines.append("")

        # ===== ç¤¾åŒºå¥åº·åº¦ç»´åº¦ =====
        lines.append("ğŸ‘¥ ã€ç¤¾åŒºå¥åº·åº¦ã€‘30åˆ†")
        lines.append("-" * 80)
        community_breakdown = scoring_breakdown["community_health"]
        community_score = community_breakdown["total_score"]
        lines.append(f"å½“å‰å¾—åˆ†: {community_score}/30 ({community_breakdown['percentage']:.1f}%)")
        lines.append(f"å¯ä¿¡åº¦: {community_breakdown['confidence']}")
        lines.append("")

        raw_community = community_breakdown["raw_metrics"]

        # Stars
        stars = raw_community["stars"]
        if stars > 0:
            star_score = min(6, __import__("math").log10(stars + 1) * 1.5)
        else:
            star_score = 0
        lines.append(f"  â­ Stars: {stars:,}")
        lines.append(f"     â†’ å¾—åˆ†: {star_score:.1f} åˆ† (å¯¹æ•°è¯„åˆ†)")

        # Forks
        forks = raw_community["forks"]
        if forks > 0:
            fork_score = min(4, __import__("math").log10(forks + 1) * 1.2)
        else:
            fork_score = 0
        lines.append(f"  ğŸ”€ Forks: {forks:,}")
        lines.append(f"     â†’ å¾—åˆ†: {fork_score:.1f} åˆ† (å¯¹æ•°è¯„åˆ†)")

        # Contributors
        contributors = raw_community["contributors"]
        if contributors > 0:
            contrib_score = min(5, __import__("math").log10(contributors + 1) * 1.8)
            contrib_level = "æ´»è·ƒ" if contributors >= 10 else "å°‘é‡"
        else:
            contrib_score = 0
            contrib_level = "æ— "
        lines.append(f"  ğŸ‘¥ è´¡çŒ®è€…: {contributors} äºº ({contrib_level})")
        lines.append(f"     â†’ å¾—åˆ†: {contrib_score:.1f} åˆ† (å¯¹æ•°è¯„åˆ†)")

        # Issueè®¨è®º
        issue_comments_avg = raw_community["issue_comments_avg"]
        if issue_comments_avg >= 3:
            discussion_level = "æ´»è·ƒ"
            discussion_score = 5
        elif issue_comments_avg >= 1:
            discussion_level = "ä¸­ç­‰"
            discussion_score = 3
        elif issue_comments_avg > 0:
            discussion_level = "ä½æ´»åŠ¨"
            discussion_score = 1
        else:
            discussion_level = "æ— è¯„è®º"
            discussion_score = 0

        lines.append(f"  ğŸ’¬ Issueè®¨è®º: å¹³å‡ {issue_comments_avg:.2f} æ¡è¯„è®º/issue ({discussion_level})")
        lines.append(f"     â†’ å¾—åˆ†: {discussion_score} åˆ†")

        # PRè¯„å®¡
        pr_density = raw_community["pr_comment_density"]
        if pr_density >= 1:
            review_level = "ä¼˜ç§€"
            review_score = 5
        elif pr_density >= 0.5:
            review_level = "è‰¯å¥½"
            review_score = 3
        elif pr_density > 0:
            review_level = "åŸºç¡€"
            review_score = 1
        else:
            review_level = "å¾…æ”¹è¿›"
            review_score = 0

        lines.append(f"  ğŸ” PRè¯„å®¡: {pr_density:.2f} æ¡è¯„è®º/merged_pr ({review_level})")
        lines.append(f"     â†’ å¾—åˆ†: {review_score} åˆ†")

        # é¡¹ç›®æˆç†Ÿåº¦
        age_years = raw_community["age_in_years"]
        age_days = raw_community["age_in_days"]
        if age_years >= 3:
            age_level = "æˆç†Ÿ"
            age_score = 2
        elif age_years >= 1:
            age_level = "å‘å±•ä¸­"
            age_score = 1
        else:
            age_level = "æ–°é¡¹ç›®"
            age_score = 0

        lines.append(f"  ğŸ“… é¡¹ç›®å¹´é¾„: {age_years:.1f} å¹´ ({age_level}) [åˆ›å»ºè‡³ä»Š: {age_days} å¤©]")
        lines.append(f"     â†’ å¾—åˆ†: {age_score} åˆ†")

        # Star/Forkæ¯”ç‡
        star_fork_ratio = raw_community["star_fork_ratio"]
        if isinstance(star_fork_ratio, (int, float)):
            if 3 <= star_fork_ratio <= 15:
                ratio_level = "å¥åº·"
                ratio_score = 2
            elif 2 <= star_fork_ratio <= 20:
                ratio_level = "å¯æ¥å—"
                ratio_score = 1
            else:
                ratio_level = "ä¸å‡"
                ratio_score = 0
        else:
            ratio_level = "æ— Fork"
            ratio_score = 0

        lines.append(f"  âš–ï¸ Star/Forkæ¯”: {star_fork_ratio} ({ratio_level})")
        lines.append(f"     â†’ å¾—åˆ†: {ratio_score} åˆ†")

        # æŒç»­ç»´æŠ¤
        maintained_years = raw_community["maintained_for_years"]
        if maintained_years >= 2:
            maintain_level = "é•¿æœŸ"
            maintain_score = 1
        else:
            maintain_level = "çŸ­æœŸ"
            maintain_score = 0

        lines.append(f"  ğŸ”§ æŒç»­ç»´æŠ¤: {maintain_level}ç»´æŠ¤ ({maintained_years:.1f} å¹´)")
        lines.append(f"     â†’ å¾—åˆ†: {maintain_score} åˆ†")

        lines.append(f"\n   ã€ç¤¾åŒºå¥åº·åº¦è¯¦æƒ…ã€‘{dict(community_breakdown['details'])}")
        lines.append("")

        # ===== æ€»ç»“ =====
        lines.append("=" * 80)
        lines.append(f"ğŸ“Š æœ€ç»ˆè¯„åˆ†: {total_score}/100")
        lines.append(f"ğŸ“ˆ è¯„çº§: {evaluation.rating}")
        lines.append(f"ğŸ¯ æ¨è: {evaluation.recommendation}")
        lines.append("=" * 80)

        if evaluation.strengths:
            lines.append("\nâœ… ä¸»è¦ä¼˜åŠ¿:")
            for strength in evaluation.strengths:
                lines.append(f"   â€¢ {strength}")

        if evaluation.weaknesses:
            lines.append("\nâš ï¸ å¯æ”¹è¿›ä¹‹å¤„:")
            for weakness in evaluation.weaknesses:
                lines.append(f"   â€¢ {weakness}")

        lines.append("")

        return "\n".join(lines)

    @staticmethod
    def to_compact_summary(evaluation: ProjectEvaluation) -> str:
        """ç”Ÿæˆç®€æ´çš„è¯„ä¼°æ‘˜è¦ï¼ˆé€‚åˆå¿«é€ŸæŸ¥çœ‹ï¼‰

        Args:
            evaluation: é¡¹ç›®è¯„ä¼°ç»“æœ

        Returns:
            ç®€æ´æ‘˜è¦
        """
        return f"""
ğŸ¯ **{evaluation.repo_full_name}** é¡¹ç›®è¯„ä¼°

ğŸ“Š ç»¼åˆè¯„åˆ†: **{evaluation.total_score:.1f}/100** ({evaluation.rating})

ğŸ“ˆ ç»´åº¦å¾—åˆ†:
  â€¢ ä»£ç è´¨é‡: {evaluation.code_quality.score:.1f}/30
  â€¢ æ´»è·ƒåº¦: {evaluation.activity.score:.1f}/40
  â€¢ ç¤¾åŒºå¥åº·åº¦: {evaluation.community_health.score:.1f}/30

ğŸ¯ å»ºè®®: {evaluation.recommendation}
""".strip()

    @staticmethod
    def generate_detailed_analysis(evaluation: ProjectEvaluation) -> dict:
        """ç”Ÿæˆè¯¦ç»†çš„åˆ†ææ•°æ®ä¾›è¿›ä¸€æ­¥å¤„ç†

        Args:
            evaluation: é¡¹ç›®è¯„ä¼°ç»“æœ

        Returns:
            åŒ…å«è¯¦ç»†åˆ†ææ•°æ®çš„å­—å…¸
        """
        return {
            "basic_info": {
                "repo_full_name": evaluation.repo_full_name,
                "repo_url": evaluation.repo_url,
                "evaluated_at": evaluation.evaluated_at.isoformat(),
            },
            "scores": {
                "total": {
                    "score": evaluation.total_score,
                    "rating": evaluation.rating,
                },
                "code_quality": {
                    "score": evaluation.code_quality.score,
                    "max_score": evaluation.code_quality.max_score,
                    "percentage": evaluation.code_quality.percentage,
                    "details": evaluation.code_quality.details,
                },
                "activity": {
                    "score": evaluation.activity.score,
                    "max_score": evaluation.activity.max_score,
                    "percentage": evaluation.activity.percentage,
                    "details": evaluation.activity.details,
                },
                "community_health": {
                    "score": evaluation.community_health.score,
                    "max_score": evaluation.community_health.max_score,
                    "percentage": evaluation.community_health.percentage,
                    "details": evaluation.community_health.details,
                },
            },
            "metrics": evaluation.key_metrics,
            "analysis": {
                "summary": evaluation.summary,
                "strengths": evaluation.strengths,
                "weaknesses": evaluation.weaknesses,
                "recommendation": evaluation.recommendation,
            },
        }
